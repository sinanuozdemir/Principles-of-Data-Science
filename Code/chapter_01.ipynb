{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS TWEET IS ABOUT $TWTR\n",
      "THIS TWEET IS ABOUT $AAPL\n"
     ]
    }
   ],
   "source": [
    "tweet = \"RT @j_o_n_dnger: $TWTR now top holding for Andor, unseating $AAPL\"\n",
    "words_in_tweet = tweet.split(' ') # list of words in tweet\n",
    "for word in words_in_tweet: # for each word in list\n",
    "    if \"$\" in word: # if word has a \"cashtag\"\n",
    "        print(\"THIS TWEET IS ABOUT\", word) # alert the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@j_o_n_dnger:',\n",
       " '$TWTR',\n",
       " 'now',\n",
       " 'top',\n",
       " 'holding',\n",
       " 'for',\n",
       " 'Andor,',\n",
       " 'unseating',\n",
       " '$AAPL']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 0\n",
      "No texts retrieved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# User-agent string to mimic a real user, this is more ethical than spoofing\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "texts = []\n",
    "for i in tqdm(range(0, 100, 10)):  # cycle through 100 pages of Indeed job resources\n",
    "    response = requests.get(f'http://www.indeed.com/jobs?q=data+scientist&start={i}', headers=headers)\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        texts += [a.text for a in soup.find_all('table', {'role': 'presentation'})]\n",
    "\n",
    "print(type(texts), len(texts))\n",
    "if texts:\n",
    "    print(texts[0])   # first truncated job description\n",
    "else:\n",
    "    print(\"No texts retrieved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code above unfortunately fails with Indeed's latest updates but I copy and pasted some HTML from Indeed to get data for us!\n",
    "\n",
    "for html in htmls:\n",
    "    texts += [a.text for a in BeautifulSoup(html, 'html.parser').find_all('table', {'role': 'presentation'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2118 features\n",
      "data 85\n",
      "learning 29\n",
      "time 28\n",
      "machine 23\n",
      "machine learning 22\n",
      "scientist 20\n",
      "000 20\n",
      "ca 18\n",
      "area 16\n",
      "data scientist 14\n",
      "health 13\n",
      "ago 12\n",
      "francisco 12\n",
      "days 11\n",
      "days ago 11\n",
      "yearfull 11\n",
      "experience 11\n",
      "senior 11\n",
      "analytics 11\n",
      "ai 9\n",
      "000 yearfull 9\n",
      "easily 9\n",
      "yearfull time 9\n",
      "science 9\n",
      "francisco ca 8\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "# make a count vectorizer to get basic counts\n",
    "\n",
    "matrix = vect.fit_transform(texts)\n",
    "# fit and learn to the vocabulary in the corpus\n",
    "\n",
    "print(f'There are {len(vect.get_feature_names_out())} features')\n",
    "\n",
    "freqs = [(word, matrix.getcol(idx).sum()) for word, idx in vect.vocabulary_.items()]\n",
    "#sort from largest to smallest\n",
    "for phrase, times in sorted (freqs, key = lambda x: -x[1])[:25]:\n",
    "    print(phrase, times)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print len(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print len(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
